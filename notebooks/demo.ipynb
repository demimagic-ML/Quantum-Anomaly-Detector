{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Anomaly Detector — Interactive Demo\n",
    "\n",
    "This notebook walks through the full pipeline of using a **Quantum Autoencoder** for financial fraud detection:\n",
    "\n",
    "1. Generate synthetic transaction data\n",
    "2. Preprocess & encode into quantum states\n",
    "3. Build & inspect the quantum circuit\n",
    "4. Train the hybrid model\n",
    "5. Evaluate anomaly detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cirq\n",
    "import sympy\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "sns.set_theme(style='whitegrid', font_scale=1.1)\n",
    "print(f'TensorFlow: {tf.__version__}')\n",
    "print(f'TFQ: {tfq.__version__}')\n",
    "print(f'Cirq: {cirq.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We create a dataset of **5,000 normal** and **500 fraudulent** transactions with 4 features:\n",
    "- `transaction_amount` — log-normal (normal) vs. inflated (fraud)\n",
    "- `time_since_last_txn` — exponential gap (normal) vs. rapid-fire (fraud)\n",
    "- `distance_from_home` — moderate (normal) vs. far away (fraud)\n",
    "- `merchant_risk_score` — low risk (normal) vs. high risk (fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.generate_data import create_dataset\n",
    "\n",
    "df, labels = create_dataset(n_normal=5000, n_fraud=500, seed=42)\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Normal: {(labels == 0).sum()}, Fraud: {(labels == 1).sum()}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions by class\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "features = ['transaction_amount', 'time_since_last_txn', 'distance_from_home', 'merchant_risk_score']\n",
    "\n",
    "for ax, feat in zip(axes.flat, features):\n",
    "    ax.hist(df[df['label'] == 0][feat], bins=50, alpha=0.7, label='Normal', color='#2196F3', density=True)\n",
    "    ax.hist(df[df['label'] == 1][feat], bins=50, alpha=0.7, label='Fraud', color='#F44336', density=True)\n",
    "    ax.set_title(feat)\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle('Feature Distributions — Normal vs. Fraud', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Quantum State Preparation\n",
    "\n",
    "We scale features to $[0, \\pi]$ and encode each sample as $R_y(x_i)|0\\rangle$ on the corresponding qubit (**angle encoding**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import scale_features, split_data, prepare_quantum_data\n",
    "from src.model.quantum_autoencoder import ALL_QUBITS\n",
    "\n",
    "X = df.drop(columns=['label']).values\n",
    "\n",
    "# Split: train on normal ONLY\n",
    "X_train, X_test, y_train, y_test = split_data(X, labels, seed=42)\n",
    "print(f'Train: {len(y_train)} samples (all normal)')\n",
    "print(f'Test:  {len(y_test)} samples (normal: {(y_test==0).sum()}, fraud: {(y_test==1).sum()})')\n",
    "\n",
    "# Scale\n",
    "X_train_scaled, scaler = scale_features(X_train)\n",
    "X_test_scaled = np.clip(scaler.transform(X_test), 0.0, np.pi)\n",
    "\n",
    "print(f'\\nScaled range: [{X_train_scaled.min():.3f}, {X_train_scaled.max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to quantum circuits\n",
    "q_train = prepare_quantum_data(X_train_scaled, ALL_QUBITS)\n",
    "q_test = prepare_quantum_data(X_test_scaled, ALL_QUBITS)\n",
    "\n",
    "print(f'Quantum train tensor: {q_train.shape}')\n",
    "print(f'Quantum test tensor:  {q_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect the Quantum Autoencoder Circuit\n",
    "\n",
    "The variational ansatz uses:\n",
    "- $R_y(\\theta)$ single-qubit rotations\n",
    "- Linear CNOT entanglement chains\n",
    "- Depth $L=3$ layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.quantum_autoencoder import create_quantum_autoencoder_circuit\n",
    "\n",
    "circuit, symbols, readouts = create_quantum_autoencoder_circuit(depth=3)\n",
    "\n",
    "print(f'Number of trainable parameters: {len(symbols)}')\n",
    "print(f'Trash qubit observables: {readouts}')\n",
    "print(f'\\nCircuit depth: {len(circuit)}')\n",
    "print(f'\\n{circuit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Quantum Autoencoder\n",
    "\n",
    "The model minimizes the **fidelity loss**: $\\mathcal{L} = 1 - \\text{mean}(\\langle Z \\rangle_{\\text{trash}})$\n",
    "\n",
    "When the loss is 0, all trash qubits are in $|0\\rangle$ — perfect compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.quantum_autoencoder import build_keras_model, fidelity_loss, NUM_TRASH_QUBITS\n",
    "\n",
    "model = build_keras_model(depth=3)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
    "    loss=fidelity_loss,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_labels = np.ones((len(y_train), NUM_TRASH_QUBITS), dtype=np.float32)\n",
    "\n",
    "history = model.fit(\n",
    "    q_train,\n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True),\n",
    "    ],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(history.history['loss'], linewidth=2, color='#4CAF50')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Fidelity Loss (1 − ⟨Z⟩)')\n",
    "ax.set_title('Training Loss — Quantum Autoencoder')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate — Anomaly Detection\n",
    "\n",
    "**Key Idea:** The autoencoder was trained *only* on normal data. Fraudulent transactions produce higher anomaly scores because the circuit cannot compress unseen patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.quantum_autoencoder import compute_anomaly_scores\n",
    "\n",
    "scores = compute_anomaly_scores(model, q_test)\n",
    "\n",
    "normal_scores = scores[y_test == 0]\n",
    "fraud_scores = scores[y_test == 1]\n",
    "\n",
    "print(f'Normal — mean score: {normal_scores.mean():.4f} ± {normal_scores.std():.4f}')\n",
    "print(f'Fraud  — mean score: {fraud_scores.mean():.4f} ± {fraud_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly score distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(normal_scores, bins=40, alpha=0.7, label='Normal', color='#2196F3', density=True)\n",
    "ax.hist(fraud_scores, bins=40, alpha=0.7, label='Fraud', color='#F44336', density=True)\n",
    "ax.set_xlabel('Anomaly Score (1 − ⟨Z⟩)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Quantum Autoencoder — Anomaly Score Distribution')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "\n",
    "# ROC Curve\n",
    "auroc = roc_auc_score(y_test, scores)\n",
    "fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.plot(fpr, tpr, linewidth=2, color='#9C27B0', label=f'QAE (AUROC = {auroc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=0.8, label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve — Fraud Detection')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_aspect('equal')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'AUROC: {auroc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Component | Detail |\n",
    "|---|---|\n",
    "| **Encoding** | Angle encoding via $R_y(x_i)$ — 4 features → 4 qubits |\n",
    "| **Ansatz** | Hardware-efficient: $R_y$ rotations + CNOT chains, depth 3 |\n",
    "| **Latent Space** | 2 latent qubits retain compressed state |\n",
    "| **Trash Qubits** | 2 trash qubits trained to collapse to $|0\\rangle$ |\n",
    "| **Cost Function** | $\\mathcal{L} = 1 - \\text{mean}(\\langle Z \\rangle_{\\text{trash}})$ |\n",
    "| **Anomaly Score** | Same as cost — high for unseen (fraud) patterns |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
